5tc1_r had ValueError, probably some of inputs are of wrong dimention. Data thrown away 
training samples 25062 from 323 PDBid, val samples 156 from 157 PDBid
Class 1 has 0.0348 percent, given 0.604908833331 weight
Class 2 has 0.0566 percent, given 0.371922745582 weight
Class 3 has 0.9086 percent, given 0.0231684210873 weight
25062 finished intitialising total number of training/val samples
['4v9e_aa', '5t2a_f', '1wz2_c', '4cxg_y', '4pr6_b', '4v8m_bf', '1kh6_a', '4cxg_a', '3amt_b', '3jcs_4', '3wqy_c', '4yb1_r', '1c9s_w', '1qzw_b', '4pjo_1', '3j45_5', '5mgp_x', '4c7o_e', '3j45_1', '3j45_2', '3a2k_c', '3j79_b', '4plx_a', '1sj3_r', '2nz4_p', '4cxg_2', '3j0p_w', '4fe5_b', '5a2q_3', '3rkf_a', '2csx_c', '4kzd_r', '4xjn_n', '4zdo_e', '3eq4_y', '5btp_a', '4mgn_a', '5hr7_c', '4wsm_3k', '4y1m_a', '5ib8_1l', '1zc8_i', '5vzl_b', '5o2r_x', '4m6d_b', '3jcs_6', '2fk6_r', '1j1u_b', '5mmi_w', '3wc1_p', '3j5s_a', '4v5z_b1', '1hq1_b', '1jgq_d', '3ktw_c', '1qzc_a', '1ml5_b', '4v6u_a0', '5xh6_b', '3hhn_c', '4yye_c', '5mmm_z', '1mj1_q', '1s03_a', '1s03_b', '4v7m_ay', '3j7a_7', '4v5z_bs', '4v5z_bn', '2zy6_a', '1gtf_w', '3j45_4', '4v5z_bg', '2hvy_e', '3q1q_c', '3j0o_h', '4o26_e', '3w1k_f', '4v7f_2', '5lzd_x', '5kpy_a', '5lzs_3', '4v8d_ab', '1pn8_d', '4v5g_ay', '1gax_c', '3moj_a', '5njt_v', '2bte_b', '5it7_8', '5mga_b', '5mc6_m', '3jbu_v', '1y27_x', '3j92_2', '2zue_b', '3izd_a', '4wf9_y', '4kqy_a', '3j0o_7', '5ktj_a', '3j0o_2', '5f9r_a', '5t5h_h', '1qf6_b', '1ysh_b', '5btm_a', '5dcv_b', '2om7_j', '2om7_i', '486d_e', '486d_a', '486d_c', '5lzs_2', '5jup_ec', '2j37_z', '1f7u_b', '1y0q_a', '1dk1_b', '3iab_r', '4qjh_b', '3dhs_a', '4v4b_b4', '3hax_e', '4tue_qv', '4adx_8', '3t4b_a', '4v8p_b3', '4v8t_1', '2nue_c', '3iwn_a', '3jaj_4', '4rdx_c', '3j2c_m', '1zc8_j', '1u63_b', '1zc8_h', '4v7e_ae', '5aj0_bv', '1zc8_a', '3q3z_a', '1nbs_a', '4m4o_b', '3d0u_a', '2j28_8', '3iyq_a', '4jxz_b', '5ddp_a', '2go5_a', '4frn_a', '1xjr_a', '5mrc_bb', '1hc8_c', '1zn1_b', '4uyk_r', '4yaz_a']
number of weights
1_wc1aa 120
1_wc1ab 960
1_wc1ac 960
1_wc1ba 120
1_wc1bb 960
1_wc1c 120
1_wc1d 120
2_wc1aa 512
2_wc1ab 3840
2_wc1ac 3840
2_wc1ba 512
2_wc1bb 3840
2_wc1c 512
2_wc1d 512
3_wc1aa 2080
3_wc1ab 15360
3_wc1ac 15360
3_wc1ba 2080
3_wc1bb 16384
3_wc1c 2080
3_wc1d 2080
4_wc1aa 2048
4_wc1ab 3840
4_wc1ac 3840
4_wc1ba 2048
4_wc1bb 4096
4_wc1c 2048
4_wc1d 2048
5_wc1aa 1024
5_wc1ab 3840
5_wc1ac 3840
5_wc1ba 1024
5_wc1bb 12544
5_wc1c 1024
5_wc1d 1024
6_wc1aa 1024
6_wc1ab 3840
6_wc1ac 3840
6_wc1ba 1024
6_wc1bb 12544
6_wc1c 1024
6_wc1d 1024
7_wc1aa 1024
7_wc1ab 3840
7_wc1ac 3840
7_wc1ba 1024
7_wc1bb 12544
7_wc1c 1024
7_wc1d 1024
9_out2 4800
170080 :total parameters
0.773985786762
Epoch: 0001 cost= 0.054917824 0.722123396352
Epoch: 0001 cost= 0.069039688 0.785882309645
0.774689024019
Epoch: 0002 cost= 0.054301813 0.748480917609
Epoch: 0002 cost= 0.069178395 0.785298778089
0.775491109202
Epoch: 0003 cost= 0.054749839 0.746959935309
Epoch: 0003 cost= 0.069287814 0.785983313954
0.777539067128
Epoch: 0004 cost= 0.054982714 0.748606850908
Epoch: 0004 cost= 0.069259323 0.787193946264
0.774234882644
Epoch: 0005 cost= 0.054110728 0.749228433384
Epoch: 0005 cost= 0.069362104 0.784356548941
0.776987306688
Epoch: 0006 cost= 0.054453023 0.758008386602
Epoch: 0006 cost= 0.069269069 0.786060715668
0.776634546799
Epoch: 0007 cost= 0.054600272 0.753838985868
Epoch: 0007 cost= 0.069205269 0.786256534478
0.776420825834
Epoch: 0008 cost= 0.054530017 0.755173217592
Epoch: 0008 cost= 0.069205873 0.785655838815
0.778035420206
Epoch: 0009 cost= 0.054635152 0.756403121008
Epoch: 0009 cost= 0.069132864 0.787087679109
0.776685924771
Epoch: 0010 cost= 0.054953232 0.758989609856
Epoch: 0010 cost= 0.069184832 0.785615883538
0.77784866923
Epoch: 0011 cost= 0.054360423 0.760943306112
Epoch: 0011 cost= 0.069076948 0.786723803031
0.778081895778
Epoch: 0012 cost= 0.054449596 0.764983850056
Epoch: 0012 cost= 0.069198631 0.786319168668
0.775696836787
Epoch: 0013 cost= 0.054051060 0.764668652818
Epoch: 0013 cost= 0.069275059 0.784905562428
0.777725345996
Epoch: 0014 cost= 0.054484479 0.75748761331
Epoch: 0014 cost= 0.069172174 0.786150963177
0.777792493878
Epoch: 0015 cost= 0.054867156 0.762919590855
Epoch: 0015 cost= 0.069195405 0.786314774716
0.779707161742
Epoch: 0016 cost= 0.053910717 0.770034254939
Epoch: 0016 cost= 0.068971068 0.788412178988
0.775825010037
Epoch: 0017 cost= 0.054539293 0.764340625012
Epoch: 0017 cost= 0.069246143 0.784462364293
0.777106913401
Epoch: 0018 cost= 0.054559432 0.759865158132
Epoch: 0018 cost= 0.069170229 0.785680766723
0.776383660651
Epoch: 0019 cost= 0.054496806 0.764562905467
Epoch: 0019 cost= 0.069136634 0.785455246364
0.776512380248
Epoch: 0020 cost= 0.054281019 0.765895119175
Epoch: 0020 cost= 0.069168039 0.785568521175
Optimization Finished!
======================================================================================

			Resource Usage on 2017-09-25 17:31:30.655533:

	JobId: 5466218.wlm01  
	Project: 13000487 
	Exit Status: 1
	NCPUs Requested: 24				NCPUs Used: 24
							CPU Time Used: 00:45:10
	Memory Requested: 110100480kb 				Memory Used: 3103892kb
							Vmem Used: 170636528kb
	Walltime requested: 23:59:00 			Walltime Used: 00:50:12
	
	Execution Nodes Used: (gpu1711:mem=110100480kb:ncpus=24:ngpus=1)
	
 ======================================================================================
